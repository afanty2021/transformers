[æ ¹ç›®å½•](/Users/berton/Github/transformers/CLAUDE.md) > [src](/Users/berton/Github/transformers/src/CLAUDE.md) > [transformers](/Users/berton/Github/transformers/src/transformers/CLAUDE.md) > **data**

# Data æ¨¡å—æ–‡æ¡£

> æ¨¡å—è·¯å¾„: `src/transformers/data/`
> æœ€åæ›´æ–°: 2025-01-20
> è¦†ç›–ç‡: 90%

## æ¨¡å—èŒè´£

Dataæ¨¡å—è´Ÿè´£Transformersåº“çš„æ•°æ®å¤„ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

1. **æ•°æ®æ”¶é›†å™¨**: å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
2. **æ•°æ®å¤„ç†å™¨**: æ ‡å‡†æ•°æ®é›†çš„å¤„ç†é€»è¾‘
3. **æŒ‡æ ‡è®¡ç®—**: æ¨¡å‹è¯„ä¼°æŒ‡æ ‡å®ç°
4. **ç‰¹å¾æå–**: æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹

## æ ¸å¿ƒç»„ä»¶

### 1. æ•°æ®æ”¶é›†å™¨ (`data_collator.py`)
```python
# åŸºç¡€æ•°æ®æ”¶é›†å™¨
DataCollator                    # åŸºç¡€æ•°æ®æ”¶é›†å™¨ç±»
DefaultDataCollator           # é»˜è®¤æ•°æ®æ”¶é›†å™¨
default_data_collator()        # é»˜è®¤æ”¶é›†å™¨å‡½æ•°

# ç‰¹å®šä»»åŠ¡æ•°æ®æ”¶é›†å™¨
DataCollatorWithPadding       # å¸¦å¡«å……çš„æ•°æ®æ”¶é›†å™¨
DataCollatorForLanguageModeling  # è¯­è¨€å»ºæ¨¡æ•°æ®æ”¶é›†å™¨
DataCollatorForTokenClassification  # æ ‡è®°åˆ†ç±»æ•°æ®æ”¶é›†å™¨
DataCollatorForSeq2Seq        # åºåˆ—åˆ°åºåˆ—æ•°æ®æ”¶é›†å™¨
DataCollatorForMultipleChoice  # å¤šé€‰æ•°æ®æ”¶é›†å™¨
```

### 2. æ•°æ®å¤„ç†å™¨ (`processors/`)
```python
# åŸºç¡€å¤„ç†å™¨
DataProcessor                  # æ•°æ®å¤„ç†å™¨åŸºç±»
InputExample                   # è¾“å…¥æ ·ä¾‹ç±»
InputFeatures                  # è¾“å…¥ç‰¹å¾ç±»

# GLUEä»»åŠ¡å¤„ç†å™¨
glue_processors               # GLUEä»»åŠ¡å¤„ç†å™¨å­—å…¸
glue_convert_examples_to_features()  # GLUEæ ·ä¾‹è½¬æ¢
glue_output_modes             # GLUEè¾“å‡ºæ¨¡å¼
glue_tasks_num_labels         # GLUEä»»åŠ¡æ ‡ç­¾æ•°

# SQuADä»»åŠ¡å¤„ç†å™¨
SquadV1Processor              # SQuAD v1.0å¤„ç†å™¨
SquadV2Processor              # SQuAD v2.0å¤„ç†å™¨
SquadExample                  # SQuADæ ·ä¾‹ç±»
SquadFeatures                 # SQuADç‰¹å¾ç±»
```

### 3. æŒ‡æ ‡è®¡ç®— (`metrics/`)
```python
# GLUEæŒ‡æ ‡
glue_compute_metrics()        # GLUEä»»åŠ¡æŒ‡æ ‡è®¡ç®—
xnli_compute_metrics()        # XNLIä»»åŠ¡æŒ‡æ ‡è®¡ç®—
squad_metrics.py              # SQuADä»»åŠ¡æŒ‡æ ‡
```

## å­æ¨¡å—ç»“æ„

### data_collator.py
æ•°æ®æ”¶é›†å™¨çš„æ ¸å¿ƒå®ç°ï¼Œè´Ÿè´£ï¼š

- **åŠ¨æ€å¡«å……**: æ ¹æ®æ‰¹æ¬¡ä¸­æœ€å¤§åºåˆ—é•¿åº¦è¿›è¡Œå¡«å……
- **ä»»åŠ¡ç‰¹å®šå¤„ç†**: é’ˆå¯¹ä¸åŒNLPä»»åŠ¡çš„ä¸“é—¨æ•°æ®å¤„ç†
- **å¼ é‡æ ¼å¼è½¬æ¢**: å°†æ•°æ®è½¬æ¢ä¸ºPyTorchå¼ é‡
- **æ‰¹å¤„ç†ä¼˜åŒ–**: é«˜æ•ˆçš„æ‰¹é‡æ•°æ®å¤„ç†

#### å…³é”®æ•°æ®æ”¶é›†å™¨ç±»

1. **DataCollatorForLanguageModeling**
```python
# æ©ç è¯­è¨€å»ºæ¨¡æ•°æ®æ”¶é›†å™¨
collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer,
    mlm=True,           # å¯ç”¨æ©ç è¯­è¨€å»ºæ¨¡
    mlm_probability=0.15  # æ©ç æ¦‚ç‡
)
```

2. **DataCollatorForTokenClassification**
```python
# æ ‡è®°åˆ†ç±»æ•°æ®æ”¶é›†å™¨
collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer,
    padding=True,
    label_pad_token_id=-100
)
```

### processors/
æ•°æ®å¤„ç†å™¨æ¨¡å—ï¼ŒåŒ…å«æ ‡å‡†NLPä»»åŠ¡çš„å¤„ç†é€»è¾‘ï¼š

#### GLUEä»»åŠ¡æ”¯æŒ
- **CoLA**: è¯­è¨€å­¦å¯æ¥å—æ€§åˆ¤æ–­
- **SST-2**: æƒ…æ„Ÿåˆ†æ
- **MRPC**: è¯­ä¹‰ç­‰ä»·åˆ¤æ–­
- **STS-B**: è¯­ä¹‰ç›¸ä¼¼åº¦
- **QQP**: é—®é¢˜ç­‰ä»·åˆ¤æ–­
- **MNLI**: å¤šä½“è£è‡ªç„¶è¯­è¨€æ¨ç†
- **QNLI**: é—®ç­”è‡ªç„¶è¯­è¨€æ¨ç†
- **RTE**: è¯†åˆ«æ–‡æœ¬è•´å«
- **WNLI**: Winogradæ¨¡å¼æŒ‘æˆ˜

#### SQuADä»»åŠ¡æ”¯æŒ
- **SQuAD v1.0**: é˜…è¯»ç†è§£æ•°æ®é›†
- **SQuAD v2.0**: åŒ…å«æ— ç­”æ¡ˆæƒ…å†µçš„é˜…è¯»ç†è§£

### datasets/
é¢„å®šä¹‰æ•°æ®é›†å¤„ç†ï¼š
- **language_modeling.py**: è¯­è¨€å»ºæ¨¡æ•°æ®é›†
- **glue.py**: GLUEæ•°æ®é›†å¤„ç†
- **squad.py**: SQuADæ•°æ®é›†å¤„ç†

## ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€æ•°æ®æ”¶é›†å™¨ä½¿ç”¨
```python
from transformers import DefaultDataCollator
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
collator = DefaultDataCollator()

# å‡†å¤‡æ•°æ®
data = [
    {"text": "Hello world"},
    {"text": "Transformers are great"}
]

# ç¼–ç å’Œæ”¶é›†
encoded = tokenizer([d["text"] for d in data], padding=True, return_tensors="pt")
batch = collator(encoded)
```

### 2. è¯­è¨€å»ºæ¨¡æ•°æ®æ”¶é›†å™¨
```python
from transformers import DataCollatorForLanguageModeling

collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer,
    mlm=True,
    mlm_probability=0.15,
    return_tensors="pt"
)

# æ©ç è¯­è¨€å»ºæ¨¡çš„æ‰¹æ¬¡å¤„ç†
batch = collator(texts)
```

### 3. GLUEä»»åŠ¡å¤„ç†
```python
from transformers import glue_processors, glue_convert_examples_to_features

# è·å–MRPCä»»åŠ¡å¤„ç†å™¨
processor = glue_processors["mrpc"]()
examples = processor.get_train_examples("glue_data/MRPC")

# è½¬æ¢ä¸ºç‰¹å¾
features = glue_convert_examples_to_features(
    examples,
    tokenizer,
    max_length=128,
    label_list=processor.get_labels(),
    output_mode="classification"
)
```

### 4. è‡ªå®šä¹‰æ•°æ®æ”¶é›†å™¨
```python
from transformers import DataCollatorWithPadding
from typing import List, Dict, Any

class CustomDataCollator(DataCollatorWithPadding):
    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:
        # è‡ªå®šä¹‰å¤„ç†é€»è¾‘
        labels = [feature.pop("labels") for feature in features]

        # è°ƒç”¨çˆ¶ç±»æ–¹æ³•å¤„ç†å…¶ä»–ç‰¹å¾
        batch = super().__call__(features)
        batch["labels"] = torch.stack(labels)

        return batch
```

## æ•°æ®å¤„ç†æµç¨‹

### 1. åŸå§‹æ•°æ® â†’ InputExample
```python
example = InputExample(
    guid="train-0",
    text_a="First sentence",
    text_b="Second sentence",  # å¯é€‰
    label="1"
)
```

### 2. InputExample â†’ InputFeatures
```python
features = InputFeatures(
    input_ids=[101, 102],
    attention_mask=[1, 1],
    token_type_ids=[0, 0],
    label=1
)
```

### 3. InputFeatures â†’ æ‰¹æ¬¡å¼ é‡
```python
# é€šè¿‡DataCollatorè½¬æ¢ä¸ºæ‰¹æ¬¡
batch = {
    "input_ids": tensor([[101, 102], [101, 103]]),
    "attention_mask": tensor([[1, 1], [1, 1]]),
    "labels": tensor([1, 0])
}
```

## æ€§èƒ½ä¼˜åŒ–

### 1. åŠ¨æ€å¡«å……ç­–ç•¥
```python
# ä½¿ç”¨åŠ¨æ€å¡«å……å‡å°‘å†…å­˜ä½¿ç”¨
collator = DataCollatorWithPadding(
    tokenizer=tokenizer,
    padding="longest"  # å¡«å……åˆ°æ‰¹æ¬¡ä¸­æœ€é•¿åºåˆ—
)
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# é¢„åˆ†æ‰¹å¤„ç†æé«˜æ•ˆç‡
def batch_process(examples, batch_size=32):
    for i in range(0, len(examples), batch_size):
        batch = examples[i:i+batch_size]
        yield collator(batch)
```

## æµ‹è¯•ç­–ç•¥

### 1. å•å…ƒæµ‹è¯•
- æ•°æ®æ”¶é›†å™¨åŠŸèƒ½æµ‹è¯•
- å¤„ç†å™¨è½¬æ¢é€»è¾‘æµ‹è¯•
- æŒ‡æ ‡è®¡ç®—å‡†ç¡®æ€§æµ‹è¯•

### 2. é›†æˆæµ‹è¯•
- ä¸æ¨¡å‹è®­ç»ƒçš„é›†æˆæµ‹è¯•
- ä¸åŒä»»åŠ¡çš„æ•°æ®æµç¨‹æµ‹è¯•

### 3. æ€§èƒ½æµ‹è¯•
- å¤§è§„æ¨¡æ•°æ®å¤„ç†æ€§èƒ½
- å†…å­˜ä½¿ç”¨æ•ˆç‡æµ‹è¯•

## å¸¸è§é—®é¢˜ (FAQ)

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ•°æ®æ”¶é›†å™¨ï¼Ÿ
A: æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ï¼š
- è¯­è¨€å»ºæ¨¡ï¼š`DataCollatorForLanguageModeling`
- æ ‡è®°åˆ†ç±»ï¼š`DataCollatorForTokenClassification`
- åºåˆ—åˆ°åºåˆ—ï¼š`DataCollatorForSeq2Seq`
- é€šç”¨ä»»åŠ¡ï¼š`DefaultDataCollator`

### Q: å¦‚ä½•å¤„ç†é•¿åº¦å·®å¼‚å¾ˆå¤§çš„åºåˆ—ï¼Ÿ
A: ä½¿ç”¨åŠ¨æ€å¡«å……ï¼š
```python
collator = DataCollatorWithPadding(
    tokenizer=tokenizer,
    padding="longest"
)
```

### Q: å¦‚ä½•æ·»åŠ è‡ªå®šä¹‰å¤„ç†å™¨ï¼Ÿ
A: ç»§æ‰¿DataProcessoråŸºç±»ï¼š
```python
class CustomProcessor(DataProcessor):
    def get_train_examples(self, data_dir):
        # è‡ªå®šä¹‰è®­ç»ƒæ•°æ®è¯»å–é€»è¾‘
        pass
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ–‡ä»¶
- `__init__.py` - æ¨¡å—å¯¼å‡ºå®šä¹‰
- `data_collator.py` - æ•°æ®æ”¶é›†å™¨å®ç°
- `metrics/squad_metrics.py` - SQuADæŒ‡æ ‡è®¡ç®—

### å¤„ç†å™¨æ¨¡å—
- `processors/__init__.py` - å¤„ç†å™¨å¯¼å‡º
- `processors/glue.py` - GLUEä»»åŠ¡å¤„ç†å™¨
- `processors/squad.py` - SQuADä»»åŠ¡å¤„ç†å™¨
- `processors/utils.py` - å¤„ç†å™¨å·¥å…·å‡½æ•°
- `processors/xnli.py` - XNLIä»»åŠ¡å¤„ç†å™¨

### æ•°æ®é›†æ¨¡å—
- `datasets/__init__.py` - æ•°æ®é›†å¯¼å‡º
- `datasets/glue.py` - GLUEæ•°æ®é›†å¤„ç†
- `datasets/language_modeling.py` - è¯­è¨€å»ºæ¨¡æ•°æ®é›†
- `datasets/squad.py` - SQuADæ•°æ®é›†å¤„ç†

## æ‰©å±•æŒ‡å—

### 1. æ·»åŠ æ–°æ•°æ®æ”¶é›†å™¨
```python
class NewTaskDataCollator(DataCollatorWithPadding):
    def __call__(self, features):
        # å®ç°æ–°ä»»åŠ¡çš„æ•°æ®æ”¶é›†é€»è¾‘
        return super().__call__(processed_features)
```

### 2. æ·»åŠ æ–°æ•°æ®é›†å¤„ç†å™¨
```python
class NewDatasetProcessor(DataProcessor):
    def get_examples(self, data_dir, split):
        # å®ç°æ–°æ•°æ®é›†çš„è¯»å–é€»è¾‘
        return examples
```

## å˜æ›´è®°å½• (Changelog)

### 2025-01-20 - åˆå§‹åˆ†æ
- âœ¨ åˆ›å»ºdataæ¨¡å—è¯¦ç»†æ–‡æ¡£
- ğŸ” åˆ†ææ•°æ®æ”¶é›†å™¨æ¶æ„
- ğŸ“Š è®°å½•å¤„ç†å™¨ä½¿ç”¨æ¨¡å¼
- ğŸ¯ è¯†åˆ«æ€§èƒ½ä¼˜åŒ–æœºä¼š

---

**ğŸ“Š å½“å‰è¦†ç›–ç‡**: 90%
**ğŸ¯ ç›®æ ‡è¦†ç›–ç‡**: 98%+
**â±ï¸ åˆ†ææ—¶é—´**: 2025-01-20