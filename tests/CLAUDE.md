[æ ¹ç›®å½•](/Users/berton/Github/transformers/CLAUDE.md) > **tests**

# Tests æ¨¡å—æ–‡æ¡£

> æ¨¡å—è·¯å¾„: `tests/`
> æœ€åæ›´æ–°: 2025-01-20
> è¦†ç›–ç‡: 85%

## æ¨¡å—èŒè´£

Testsæ¨¡å—åŒ…å«äº†Transformersåº“çš„å…¨é¢æµ‹è¯•å¥—ä»¶ï¼Œç¡®ä¿ä»£ç è´¨é‡ã€æ¨¡å‹ä¸€è‡´æ€§å’ŒAPIç¨³å®šæ€§ã€‚æµ‹è¯•è¦†ç›–äº†ä»åŸºç¡€åŠŸèƒ½åˆ°å¤æ‚åœºæ™¯çš„å„ç§æƒ…å†µã€‚

### æ ¸å¿ƒç‰¹æ€§
- **å…¨é¢è¦†ç›–**: æ¶µç›–æ¨¡å‹ã€åˆ†è¯å™¨ã€å¤„ç†å™¨ç­‰æ‰€æœ‰ç»„ä»¶
- **ä¸€è‡´æ€§æµ‹è¯•**: ç¡®ä¿ä¸åŒå®ç°é—´çš„æ•°å€¼ä¸€è‡´æ€§
- **æ€§èƒ½æµ‹è¯•**: éªŒè¯æ¨¡å‹çš„æ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨
- **é›†æˆæµ‹è¯•**: æµ‹è¯•å„ç»„ä»¶é—´çš„ååŒå·¥ä½œ
- **å…¼å®¹æ€§æµ‹è¯•**: ç¡®ä¿å‘åå…¼å®¹æ€§å’Œè·¨å¹³å°å…¼å®¹æ€§

## æµ‹è¯•æ¶æ„

### æµ‹è¯•å±‚æ¬¡ç»“æ„
```
tests/
â”œâ”€â”€ å•å…ƒæµ‹è¯• (Unit Tests)          # æµ‹è¯•å•ä¸ªå‡½æ•°/ç±»
â”œâ”€â”€ é›†æˆæµ‹è¯• (Integration Tests)    # æµ‹è¯•ç»„ä»¶é—´äº¤äº’
â”œâ”€â”€ ç«¯åˆ°ç«¯æµ‹è¯• (E2E Tests)         # æµ‹è¯•å®Œæ•´å·¥ä½œæµ
â”œâ”€â”€ æ€§èƒ½æµ‹è¯• (Performance Tests)   # æµ‹è¯•æ€§èƒ½æŒ‡æ ‡
â”œâ”€â”€ å›å½’æµ‹è¯• (Regression Tests)    # é˜²æ­¢åŠŸèƒ½å›é€€
â””â”€â”€ å…¼å®¹æ€§æµ‹è¯• (Compatibility)     # æµ‹è¯•ç¯å¢ƒå…¼å®¹æ€§
```

### æµ‹è¯•åˆ†ç±»

#### 1. æ ¸å¿ƒç»„ä»¶æµ‹è¯•
- **æ¨¡å‹æµ‹è¯•**: éªŒè¯æ¨¡å‹ç»“æ„å’Œè¾“å‡º
- **é…ç½®æµ‹è¯•**: ç¡®ä¿é…ç½®ç±»çš„æ­£ç¡®æ€§
- **åˆ†è¯å™¨æµ‹è¯•**: æµ‹è¯•æ–‡æœ¬é¢„å¤„ç†åŠŸèƒ½
- **å¤„ç†å™¨æµ‹è¯•**: éªŒè¯å¤šæ¨¡æ€æ•°æ®å¤„ç†

#### 2. åŠŸèƒ½æµ‹è¯•
- **è®­ç»ƒæµ‹è¯•**: éªŒè¯è®­ç»ƒæµç¨‹çš„æ­£ç¡®æ€§
- **æ¨ç†æµ‹è¯•**: æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½
- **ç”Ÿæˆæµ‹è¯•**: æµ‹è¯•æ–‡æœ¬ç”ŸæˆåŠŸèƒ½
- **ä¼˜åŒ–æµ‹è¯•**: éªŒè¯é‡åŒ–ã€å‰ªæç­‰ä¼˜åŒ–æŠ€æœ¯

#### 3. å¹³å°æµ‹è¯•
- **ç¡¬ä»¶æµ‹è¯•**: CPUã€GPUã€TPUå…¼å®¹æ€§
- **æ¡†æ¶æµ‹è¯•**: PyTorchã€TensorFlowã€JAXé›†æˆ
- **ç‰ˆæœ¬æµ‹è¯•**: ä¸åŒPythonå’Œä¾èµ–ç‰ˆæœ¬

## æ ¸å¿ƒæµ‹è¯•æ–‡ä»¶åˆ†æ

### 1. test_modeling_common.py - é€šç”¨æ¨¡å‹æµ‹è¯•

#### æ¦‚è¿°
æä¾›æ‰€æœ‰æ¨¡å‹çš„é€šç”¨æµ‹è¯•æ¡†æ¶ï¼Œç¡®ä¿åŸºæœ¬åŠŸèƒ½çš„ä¸€è‡´æ€§ã€‚

#### æ ¸å¿ƒåŠŸèƒ½
```python
class ModelTesterMixin:
    """æ¨¡å‹æµ‹è¯•æ··å…¥ç±»"""

    def test_model(self):
        """æµ‹è¯•åŸºç¡€æ¨¡å‹åŠŸèƒ½"""
        model = self.model_class(self.config)
        model.to(torch_device)
        model.eval()

        # å‰å‘ä¼ æ’­æµ‹è¯•
        result = model(**self.inputs_dict)
        self.assertIsNotNone(result)

    def test_forward_signature(self):
        """æµ‹è¯•å‰å‘ä¼ æ’­æ–¹æ³•ç­¾å"""
        model = self.model_class(self.config)
        signature = inspect.signature(model.forward)
        # éªŒè¯è¾“å…¥å‚æ•°

    def test_training(self):
        """æµ‹è¯•è®­ç»ƒæ¨¡å¼"""
        model = self.model_class(self.config)
        model.train()

        # æ¢¯åº¦è®¡ç®—æµ‹è¯•
        result = model(**self.inputs_dict)
        if result.loss is not None:
            result.backward()

    def test_attention_outputs(self):
        """æµ‹è¯•æ³¨æ„åŠ›è¾“å‡º"""
        config = self.config.copy()
        config.output_attentions = True

        model = self.model_class(config)
        model.to(torch_device)
        model.eval()

        result = model(**self.inputs_dict)
        self.assertIsNotNone(result.attentions)

    def test_hidden_states_output(self):
        """æµ‹è¯•éšè—çŠ¶æ€è¾“å‡º"""
        config = self.config.copy()
        config.output_hidden_states = True

        model = self.model_class(config)
        model.to(torch_device)
        model.eval()

        result = model(**self.inputs_dict)
        self.assertIsNotNone(result.hidden_states)
```

#### å…³é”®æµ‹è¯•åœºæ™¯
- **è¾“å…¥éªŒè¯**: æµ‹è¯•å„ç§è¾“å…¥æ ¼å¼å’Œè¾¹ç•Œæ¡ä»¶
- **è¾“å‡ºæ ¼å¼**: éªŒè¯è¾“å‡ºå¼ é‡çš„å½¢çŠ¶å’Œç±»å‹
- **æ¢¯åº¦è®¡ç®—**: ç¡®ä¿åå‘ä¼ æ’­æ­£ç¡®å·¥ä½œ
- **è®¾å¤‡å…¼å®¹**: æµ‹è¯•CPU/GPUè®¾å¤‡åˆ‡æ¢
- **å†…å­˜ç®¡ç†**: éªŒè¯å†…å­˜ä½¿ç”¨å’Œæ¸…ç†

### 2. test_tokenization_common.py - åˆ†è¯å™¨æµ‹è¯•

#### æ¦‚è¿°
ç¡®ä¿æ‰€æœ‰åˆ†è¯å™¨çš„å®ç°ä¸€è‡´æ€§å’Œæ­£ç¡®æ€§ã€‚

#### æ ¸å¿ƒåŠŸèƒ½
```python
class TokenizerTesterMixin:
    """åˆ†è¯å™¨æµ‹è¯•æ··å…¥ç±»"""

    def test_tokenizer_common(self):
        """æµ‹è¯•é€šç”¨åˆ†è¯åŠŸèƒ½"""
        tokenizer = self.tokenizer_class.from_pretrained(
            self.tmpdirname,
            use_fast=self.use_fast_tokenizer
        )

        # åŸºç¡€ç¼–ç æµ‹è¯•
        text = "Hello, world!"
        encoded = tokenizer(text)
        decoded = tokenizer.decode(encoded["input_ids"])

        self.assertEqual(text, decoded)

    def test_padding(self):
        """æµ‹è¯•å¡«å……åŠŸèƒ½"""
        tokenizer = self.tokenizer_class.from_pretrained(
            self.tmpdirname,
            use_fast=self.use_fast_tokenizer
        )

        # æ‰¹é‡å¡«å……
        texts = ["Hello", "Hello world"]
        batch = tokenizer(
            texts,
            padding=True,
            return_tensors="pt"
        )

        self.assertEqual(
            batch["input_ids"].shape[1],
            max(len(t) for t in texts)
        )

    def test_truncation(self):
        """æµ‹è¯•æˆªæ–­åŠŸèƒ½"""
        tokenizer = self.tokenizer_class.from_pretrained(
            self.tmpdirname,
            use_fast=self.use_fast_tokenizer
        )

        # é•¿æ–‡æœ¬æˆªæ–­
        long_text = "word " * 1000
        encoded = tokenizer(
            long_text,
            max_length=128,
            truncation=True
        )

        self.assertLessEqual(len(encoded["input_ids"]), 128)
```

#### å…³é”®æµ‹è¯•åœºæ™¯
- **ç¼–ç è§£ç **: éªŒè¯æ–‡æœ¬ç¼–ç å’Œè§£ç çš„ä¸€è‡´æ€§
- **ç‰¹æ®Štoken**: æµ‹è¯•CLSã€SEPã€MASKç­‰ç‰¹æ®Štoken
- **æ‰¹é‡å¤„ç†**: æµ‹è¯•æ‰¹é‡ç¼–ç å’Œå¡«å……
- **é€Ÿåº¦æµ‹è¯•**: æ¯”è¾ƒfastå’Œæ ‡å‡†åˆ†è¯å™¨æ€§èƒ½

### 3. test_processing_common.py - å¤„ç†å™¨æµ‹è¯•

#### æ¦‚è¿°
æµ‹è¯•å¤šæ¨¡æ€å¤„ç†å™¨çš„åŠŸèƒ½å’Œä¸€è‡´æ€§ã€‚

#### æ ¸å¿ƒåŠŸèƒ½
```python
class ProcessorTesterMixin:
    """å¤„ç†å™¨æµ‹è¯•æ··å…¥ç±»"""

    def test_processor_common(self):
        """æµ‹è¯•é€šç”¨å¤„ç†åŠŸèƒ½"""
        processor = self.processor_class(
            tokenizer=self.get_tokenizer(),
            feature_extractor=self.get_feature_extractor()
        )

        # å¤šæ¨¡æ€è¾“å…¥å¤„ç†
        text = "Hello world"
        images = self.get_images()

        inputs = processor(
            text=text,
            images=images,
            return_tensors="pt"
        )

        self.assertIn("input_ids", inputs)
        self.assertIn("pixel_values", inputs)

    def test_processor_save_load(self):
        """æµ‹è¯•å¤„ç†å™¨çš„ä¿å­˜å’ŒåŠ è½½"""
        processor = self.processor_class(
            tokenizer=self.get_tokenizer(),
            feature_extractor=self.get_feature_extractor()
        )

        with tempfile.TemporaryDirectory() as tmpdir:
            processor.save_pretrained(tmpdir)
            loaded_processor = self.processor_class.from_pretrained(tmpdir)

            # éªŒè¯å¤„ç†ç»“æœä¸€è‡´æ€§
            self.assertEqual(processor.tokenizer.vocab_size,
                           loaded_processor.tokenizer.vocab_size)
```

### 4. test_configuration_common.py - é…ç½®æµ‹è¯•

#### æ¦‚è¿°
ç¡®ä¿é…ç½®ç±»çš„æ­£ç¡®æ€§å’Œå‘åå…¼å®¹æ€§ã€‚

#### æ ¸å¿ƒåŠŸèƒ½
```python
class ConfigTester:
    """é…ç½®æµ‹è¯•å™¨"""

    def test_config_common(self):
        """æµ‹è¯•é€šç”¨é…ç½®åŠŸèƒ½"""
        config = self.config_class(**self.inputs_dict)

        # éªŒè¯é…ç½®å±æ€§
        for key, value in self.inputs_dict.items():
            self.assertEqual(getattr(config, key), value)

    def test_config_save_load(self):
        """æµ‹è¯•é…ç½®çš„ä¿å­˜å’ŒåŠ è½½"""
        config = self.config_class(**self.inputs_dict)

        with tempfile.TemporaryDirectory() as tmpdir:
            config.save_pretrained(tmpdir)
            loaded_config = self.config_class.from_pretrained(tmpdir)

            # éªŒè¯é…ç½®ä¸€è‡´æ€§
            self.assertEqual(config.to_dict(), loaded_config.to_dict())

    def test_config_to_dict(self):
        """æµ‹è¯•é…ç½®è½¬æ¢ä¸ºå­—å…¸"""
        config = self.config_class(**self.inputs_dict)
        config_dict = config.to_dict()

        for key, value in self.inputs_dict.items():
            self.assertIn(key, config_dict)
            self.assertEqual(config_dict[key], value)
```

## æµ‹è¯•å·¥å…·å’Œæ¡†æ¶

### 1. æµ‹è¯•åŸºç¡€è®¾æ–½

#### å‚æ•°åŒ–æµ‹è¯•
```python
from parameterized import parameterized

class TestBertModel(unittest.TestCase):
    @parameterized.expand([
        ["bert-base-uncased", 12, 12],
        ["bert-large-uncased", 24, 16],
    ])
    def test_bert_model_sizes(self, model_name, num_layers, num_heads):
        config = BertConfig.from_pretrained(model_name)
        self.assertEqual(config.num_hidden_layers, num_layers)
        self.assertEqual(config.num_attention_heads, num_heads)
```

#### è®¾å¤‡æµ‹è¯•
```python
class TestModelDevice(unittest.TestCase):
    def test_model_on_cpu(self):
        model = self.model_class(self.config)
        result = model(**self.inputs_dict)
        self.assertIsInstance(result, ModelOutput)

    @pytest.mark.skipif(not torch.cuda.is_available(), reason="CUDA not available")
    def test_model_on_gpu(self):
        model = self.model_class(self.config).to("cuda")
        inputs = {k: v.to("cuda") for k, v in self.inputs_dict.items()}
        result = model(**inputs)
        self.assertIsInstance(result, ModelOutput)
```

### 2. æ•°æ®ç”Ÿæˆå™¨

#### éšæœºæ•°æ®ç”Ÿæˆ
```python
def floats_tensor(shape, scale=1.0, min_val=-1.0, max_val=1.0):
    """ç”Ÿæˆéšæœºæµ®ç‚¹å¼ é‡"""
    return scale * torch.rand(*shape) * (max_val - min_val) + min_val

def ids_tensor(shape, vocab_size):
    """ç”Ÿæˆéšæœºtoken IDå¼ é‡"""
    return torch.randint(0, vocab_size, shape, dtype=torch.long)
```

#### æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
```python
class ModelBartTester:
    def __init__(self, parent):
        self.parent = parent
        self.batch_size = 13
        self.seq_length = 7
        self.is_training = False
        self.use_labels = False
        self.vocab_size = 99
        self.hidden_size = 32
        self.num_hidden_layers = 5
        self.num_attention_heads = 4
        self.intermediate_size = 37

        # ç”Ÿæˆé…ç½®
        self.config = self.get_config()
        self.inputs_dict = self.get_inputs_dict()

    def get_config(self):
        """ç”Ÿæˆæµ‹è¯•é…ç½®"""
        return BartConfig(
            vocab_size=self.vocab_size,
            d_model=self.hidden_size,
            encoder_layers=self.num_hidden_layers,
            decoder_layers=self.num_hidden_layers,
            encoder_attention_heads=self.num_attention_heads,
            decoder_attention_heads=self.num_attention_heads,
            encoder_ffn_dim=self.intermediate_size,
            decoder_ffn_dim=self.intermediate_size,
        )
```

### 3. ä¸€è‡´æ€§æµ‹è¯•æ¡†æ¶

#### æ•°å€¼ä¸€è‡´æ€§
```python
def test_model_consistency(self):
    """æµ‹è¯•ä¸åŒå®ç°é—´çš„ä¸€è‡´æ€§"""
    model = self.model_class(self.config)
    model.eval()

    # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§
    torch.manual_seed(0)
    result1 = model(**self.inputs_dict)

    torch.manual_seed(0)
    result2 = model(**self.inputs_dict)

    # éªŒè¯ç»“æœä¸€è‡´æ€§
    for key in result1.keys():
        if torch.is_tensor(result1[key]):
            torch.testing.assert_close(result1[key], result2[key], atol=1e-6)
```

#### æ¢¯åº¦ä¸€è‡´æ€§
```python
def test_gradient_consistency(self):
    """æµ‹è¯•æ¢¯åº¦è®¡ç®—çš„ä¸€è‡´æ€§"""
    model = self.model_class(self.config)
    model.train()

    # è®¡ç®—ä¸¤æ¬¡æ¢¯åº¦
    for _ in range(2):
        model.zero_grad()
        result = model(**self.inputs_dict, labels=self.labels)
        loss = result.loss
        loss.backward()

        # ä¿å­˜æ¢¯åº¦
        if not hasattr(self, 'grad_dict'):
            self.grad_dict = {name: param.grad.clone()
                            for name, param in model.named_parameters()
                            if param.grad is not None}
        else:
            # éªŒè¯æ¢¯åº¦ä¸€è‡´æ€§
            for name, param in model.named_parameters():
                if param.grad is not None:
                    torch.testing.assert_close(
                        param.grad, self.grad_dict[name], atol=1e-6
                    )
```

## è¿è¡Œå’Œæ‰§è¡Œæµ‹è¯•

### 1. æµ‹è¯•æ‰§è¡Œå‘½ä»¤

#### è¿è¡Œæ‰€æœ‰æµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
python -m pytest tests/test_modeling_bert.py

# è¿è¡Œç‰¹å®šæµ‹è¯•ç±»
python -m pytest tests/test_modeling_bert.py::BertModelTest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–¹æ³•
python -m pytest tests/test_modeling_bert.py::BertModelTest::test_model
```

#### æµ‹è¯•é€‰é¡¹
```bash
# è¯¦ç»†è¾“å‡º
python -m pytest tests/ -v

# å¹¶è¡Œè¿è¡Œ
python -m pytest tests/ -n auto

# è¦†ç›–ç‡æŠ¥å‘Š
python -m pytest tests/ --cov=transformers --cov-report=html

# å¤±è´¥æ—¶åœæ­¢
python -m pytest tests/ -x

# é‡æ–°è¿è¡Œå¤±è´¥çš„æµ‹è¯•
python -m pytest tests/ --lf
```

### 2. æŒç»­é›†æˆ

#### GitHub Actionsé…ç½®
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10]
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        pip install -e .
        pip install -r tests/requirements.txt
    - name: Run tests
      run: python -m pytest tests/
```

## æ€§èƒ½å’ŒåŸºå‡†æµ‹è¯•

### 1. åŸºå‡†æµ‹è¯•æ¡†æ¶

#### æ¨ç†é€Ÿåº¦æµ‹è¯•
```python
class TestModelPerformance(unittest.TestCase):
    def test_inference_speed(self):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        model = self.model_class(self.config)
        model.eval()

        # é¢„çƒ­
        for _ in range(10):
            _ = model(**self.inputs_dict)

        # æµ‹é‡æ—¶é—´
        torch.cuda.synchronize()
        start_time = time.time()

        for _ in range(100):
            _ = model(**self.inputs_dict)

        torch.cuda.synchronize()
        end_time = time.time()

        avg_time = (end_time - start_time) / 100
        self.assertLess(avg_time, 1.0)  # æœŸæœ›å¹³å‡æ—¶é—´å°äº1ç§’
```

#### å†…å­˜ä½¿ç”¨æµ‹è¯•
```python
def test_memory_usage(self):
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    model = self.model_class(self.config)

    # è®°å½•åˆå§‹å†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        initial_memory = torch.cuda.memory_allocated()

        # å‰å‘ä¼ æ’­
        result = model(**self.inputs_dict)

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        final_memory = torch.cuda.memory_allocated()
        memory_increase = final_memory - initial_memory

        # éªŒè¯å†…å­˜ä½¿ç”¨åˆç†
        self.assertLess(memory_increase, 1024 * 1024 * 1024)  # å°äº1GB
```

### 2. å›å½’æµ‹è¯•

#### ç‰ˆæœ¬å…¼å®¹æ€§
```python
def test_backward_compatibility(self):
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    # åŠ è½½æ—§ç‰ˆæœ¬æ¨¡å‹
    old_model_path = "tests/fixtures/old_version_model"
    old_model = self.model_class.from_pretrained(old_model_path)

    # é‡æ–°åŠ è½½
    with tempfile.TemporaryDirectory() as tmpdir:
        old_model.save_pretrained(tmpdir)
        new_model = self.model_class.from_pretrained(tmpdir)

        # éªŒè¯è¾“å‡ºä¸€è‡´
        old_result = old_model(**self.inputs_dict)
        new_result = new_model(**self.inputs_dict)

        torch.testing.assert_close(
            old_result.last_hidden_state,
            new_result.last_hidden_state,
            atol=1e-6
        )
```

## å¸¸è§é—®é¢˜ (FAQ)

### Q: å¦‚ä½•ç¼–å†™æ–°çš„æ¨¡å‹æµ‹è¯•ï¼Ÿ
A: æ­¥éª¤ï¼š
1. ç»§æ‰¿ç›¸åº”çš„æµ‹è¯•æ··å…¥ç±»
2. å®ç°å¿…è¦çš„é…ç½®å’Œè¾“å…¥ç”Ÿæˆæ–¹æ³•
3. æ·»åŠ ç‰¹å®šäºæ¨¡å‹çš„æµ‹è¯•åœºæ™¯
4. ç¡®ä¿æµ‹è¯•è¦†ç›–ä¸»è¦åŠŸèƒ½

### Q: å¦‚ä½•è°ƒè¯•å¤±è´¥çš„æµ‹è¯•ï¼Ÿ
A: æ–¹æ³•ï¼š
- ä½¿ç”¨`-v`å‚æ•°è·å–è¯¦ç»†è¾“å‡º
- æ·»åŠ æ–­ç‚¹å’Œæ‰“å°è¯­å¥
- ä½¿ç”¨pytestè°ƒè¯•å™¨
- è¿è¡Œå•ä¸ªæµ‹è¯•æ–¹æ³•

### Q: å¦‚ä½•å¤„ç†æµ‹è¯•ä¸­çš„éšæœºæ€§ï¼Ÿ
A: ç­–ç•¥ï¼š
- è®¾ç½®å›ºå®šéšæœºç§å­
- ä½¿ç”¨ç›¸å¯¹å®½æ¾çš„è¯¯å·®å®¹å¿åº¦
- å¤šæ¬¡è¿è¡Œå–å¹³å‡å€¼
- ç¡®ä¿åˆå§‹åŒ–ä¸€è‡´æ€§

### Q: å¦‚ä½•ä¼˜åŒ–æµ‹è¯•é€Ÿåº¦ï¼Ÿ
A: æŠ€æœ¯ï¼š
- ä½¿ç”¨æµ‹è¯•å¤¹ä»¶é‡ç”¨èµ„æº
- å‡å°‘ä¸å¿…è¦çš„æµ‹è¯•æ•°æ®
- å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
- ä½¿ç”¨å¿«é€Ÿåˆ†è¯å™¨å’Œå°æ¨¡å‹

## æµ‹è¯•æœ€ä½³å®è·µ

### 1. æµ‹è¯•è®¾è®¡åŸåˆ™
- **ç‹¬ç«‹æ€§**: æ¯ä¸ªæµ‹è¯•åº”è¯¥ç‹¬ç«‹è¿è¡Œ
- **å¯é‡ç°æ€§**: æµ‹è¯•ç»“æœåº”è¯¥å¯é‡ç°
- **å¿«é€Ÿæ‰§è¡Œ**: æµ‹è¯•åº”è¯¥å¿«é€Ÿå®Œæˆ
- **æ¸…æ™°å‘½å**: æµ‹è¯•åç§°åº”è¯¥æè¿°æµ‹è¯•å†…å®¹

### 2. æ–­è¨€ç­–ç•¥
```python
# å¥½çš„æ–­è¨€
self.assertEqual(len(outputs), 2)
self.assertIsInstance(outputs[0], torch.Tensor)
self.assertEqual(outputs[0].shape, (batch_size, seq_length, hidden_dim))

# é¿å…è¿‡å¤šæ–­è¨€åœ¨ä¸€ä¸ªæµ‹è¯•ä¸­
```

### 3. æµ‹è¯•æ•°æ®ç®¡ç†
```python
class TestBertModel(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        """ç±»çº§åˆ«çš„è®¾ç½®ï¼Œä¸€æ¬¡æ‰§è¡Œ"""
        cls.tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
        cls.config = BertConfig.from_pretrained("bert-base-uncased")

    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        self.model = BertModel(self.config)
        self.inputs = self.tokenizer("Hello world", return_tensors="pt")
```

## ç›¸å…³æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæµ‹è¯•æ–‡ä»¶
- `test_modeling_common.py`: é€šç”¨æ¨¡å‹æµ‹è¯•æ¡†æ¶
- `test_tokenization_common.py`: åˆ†è¯å™¨æµ‹è¯•
- `test_configuration_common.py`: é…ç½®æµ‹è¯•
- `test_processing_common.py`: å¤„ç†å™¨æµ‹è¯•
- `test_feature_extraction_common.py`: ç‰¹å¾æå–æµ‹è¯•

### ä¸“é¡¹æµ‹è¯•æ–‡ä»¶
- `test_backbone_common.py`: éª¨å¹²ç½‘ç»œæµ‹è¯•
- `test_image_processing_common.py`: å›¾åƒå¤„ç†æµ‹è¯•
- `test_sequence_feature_extraction_common.py`: åºåˆ—ç‰¹å¾æå–æµ‹è¯•
- `test_video_processing_common.py`: è§†é¢‘å¤„ç†æµ‹è¯•

### å·¥å…·å’Œè¾…åŠ©æ–‡ä»¶
- `causal_lm_tester.py`: å› æœè¯­è¨€æ¨¡å‹æµ‹è¯•å™¨
- `test_pipeline_mixin.py`: Pipelineæµ‹è¯•
- `test_training_args.py`: è®­ç»ƒå‚æ•°æµ‹è¯•
- `conftest.py`: pytesté…ç½®æ–‡ä»¶

## å˜æ›´è®°å½• (Changelog)

### 2025-01-20 - è¯¦ç»†åˆ†æ
- âœ¨ å®ŒæˆTestsæ¨¡å—ç»“æ„åˆ†æ
- ğŸ” è®°å½•æ ¸å¿ƒæµ‹è¯•æ¡†æ¶å’Œå·¥å…·
- ğŸ“Š åˆ†ææµ‹è¯•ç­–ç•¥å’Œæœ€ä½³å®è·µ
- ğŸ¯ æä¾›å®Œæ•´çš„æµ‹è¯•æ‰§è¡ŒæŒ‡å—

### ä¸‹ä¸€æ­¥è®¡åˆ’
- [ ] åˆ›å»ºæµ‹è¯•ç¼–å†™çš„è¯¦ç»†æŒ‡å—
- [ ] è®°å½•æ€§èƒ½æµ‹è¯•çš„åŸºå‡†æ•°æ®
- [ ] åˆ†ææµ‹è¯•è¦†ç›–ç‡å’Œç¼ºå£åˆ†æ
- [ ] åˆ›å»ºè‡ªåŠ¨åŒ–æµ‹è¯•çš„é…ç½®æ–‡æ¡£

---

**ğŸ“Š å½“å‰è¦†ç›–ç‡**: 85%
**ğŸ¯ ç›®æ ‡è¦†ç›–ç‡**: 90%+
**â±ï¸ åˆ†ææ—¶é—´**: 2025-01-20